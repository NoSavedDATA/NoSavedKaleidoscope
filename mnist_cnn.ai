import default nsk_cuda
import default networks
import glob

start_timer()





class Convs
    Conv2d conv1, conv2

    def float __init__()
        Conv2d[1,5,5,2,1,he_normal_relu] self.conv1
        Conv2d[5,50,5,2,0,he_normal_relu] self.conv2

    def tensor forward(t x)
        x = self.conv1(x)
        x = self.conv2(x)
        return x

class Model
    Convs conv
    Linear w1, w2

    def float __init__()
        self.conv.__init__()
        Linear[1250, 100, xavu_relu, param] self.w1
        Linear[100, 10, xavu, param] self.w2
        

    def tensor forward(t x)

        x = self.conv.forward(x)

        x = x.view(-1,5*5*50)

        x = self.w1(x)
        x = relu(x)
        x = self.w2(x)

        return x



class Dataset
    int batch_size, yield_ptr, _len, num_workers
    str_vec files
    pinned_tensor p_x, p_y
    int channel load_ch

    def float __init__(i batch_size, i num_workers)
        self.batch_size = batch_size
        self.num_workers = num_workers
            
        self.files = glob("/home/nosaveddata/mnist/training/*/*.png")

        
        self.yield_ptr = 0
        self._len = 0


        int channel 3 load_ch
        self.load_ch = load_ch


        pinned_tensor[num_workers, batch_size, 1,28,28] self.p_x
        pinned_tensor[num_workers, batch_size] self.p_y

    def int len()
        self._len  = LenStrVec(self.files)
        self.files = ShuffleStrVec(self.files)
        self._len


    def float terminate_workers()
        print("Terminating workers")
        self.load_ch.terminate()


    def int increment_yield_ptr()
        lock "yield"
            if (self.yield_ptr + self.batch_size*(self.num_workers+2)) > self._len
                self.yield_ptr = 0
                self.files = ShuffleStrVec(self.files)
            else
                self.yield_ptr = self.yield_ptr + self.batch_size
        self.yield_ptr


    
    def float getitem_w(i idx, i b, i w)
        var aux = self.files[idx]

        wload_img(self.p_x, aux, w, b)
        
        float aa = aux.split_idx("/", -2).to_float()
        

        self.p_y[w,b] = aa
        


    def float worker()
        print("Start worker")

        int yield_ptr, bs=self.batch_size, w=tid()

        while self.load_ch.alive()
            yield_ptr = self.increment_yield_ptr()
            
            for b=0, b < bs
                self.getitem_w(yield_ptr+b, b, w)
                
            self.load_ch <- w


    def list attr_w(t x, t y)
        int w <- self.load_ch

                
        x.gpuw(self.p_x, w)
        y.gpuw(self.p_y, w)
        

        return x, y



main
    int batch_size = 32 


    Model model()
    Dataset dataset(batch_size, 3)

    dataset.len()


    # infer_mode(model)

    finish
        asyncs 3 dataset.worker()
        

        for i=0, i<1000
            print("i: "+i)
            tensor[0] x
            tensor[0] y
            


            x, y = dataset.attr_w(x, y)


            x = model.forward(x)
            y = y.onehot(10)

            # y.print()
            # cross_entropy_idx(x, y, 0.0)
            cross_entropy(x, y, 0.0)

            backprop()

            AdamW(0.0001, 0.9, 0.999, 0.01, 1.0)

        dataset.terminate_workers()




    print("Finished eval. Get new tensor")

    tensor[1,1,28,28] x


    print("Loading image")

    # load_preprocess_img(x, "/home/nosaveddata/mnist/testing/0/3.png")
    # load_preprocess_img(x, "/home/nosaveddata/mnist/testing/1/489.png")
    # load_preprocess_img(x, "/home/nosaveddata/mnist/testing/2/35.png")
    # load_preprocess_img(x, "/home/nosaveddata/mnist/testing/4/27.png")
    load_preprocess_img(x, "/home/nosaveddata/mnist/testing/9/662.png")


    x = x.view(1,1,28,28)

    x = model.forward(x)
    print("Pre softmax")
    x.print()
    x = softmax(x)
    print("Post softmax")
    x.print()


    end_timer()